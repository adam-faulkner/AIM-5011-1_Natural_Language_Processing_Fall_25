{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBw__kO4P8-h"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Y-J2rmH47c9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KbGaKcUP8-j"
      },
      "source": [
        "#Assignment 3: Part 2\n",
        "\n",
        "Assignment 2 touches on topics covered in classes 6 and 7. Please refer to the decks and code supplements for those two classes for background. Specifically, the assignment touches on\n",
        "* Finetuning language models for classification tasks\n",
        "* Zero and few-shot prompting of LLMs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetuning BERT for Named Entity Recognition\n",
        "\n",
        "For this question, you'll be asked to finetune BERT for the task of [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)(NER) and to report out performance results. You have the following resources:\n",
        "\n",
        " * `Assignment_3_part_2_code_supplement_BERT_based_finetuning_for_sentiment.ipynb` This notebook contains basic code for finetuning BERT for sentiment analysis but you'll need to modify this code or replace it entirely for this task. `bert-base-uncased` should perform well on NER. Feel free to draw on examples that you find online for this part of the task.\n",
        " * Data: The CONLL-2003 dataset has been made available in the same folder as Assignment 3 in the file `conll_2003_ner.zip` Use this data to train and test your finetuned BERT\n",
        " * A description of the data format from [the original paper](https://aclanthology.org/W03-0419.pdf). Feel free to draw on any other info that find online.\n",
        "\n",
        "For full credit please submit a notebook `assignment_3_part2_{your_name}.ipynb` with {your_name} replaced with your name. The notebook should contain the following:\n",
        " * All of code that you used to train and test your finetuned-BERT\n",
        " * You'll be evaluating model performance on the test sets `eng.testa` and `eng.testb` found in the data folder `conll_2003_ner.zip`. Use the _span-based F1_ evaluation metric on each test set and report out the scores.\n",
        " * An answer to the question \"How does the performance of your system compare to [the state-of-the-art](https://nlpprogress.com/english/named_entity_recognition.html) for this dataset?\"\n"
      ],
      "metadata": {
        "id": "tdN5hK6zbR3H"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}